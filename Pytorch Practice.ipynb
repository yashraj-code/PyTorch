{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensor ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A tensor id ofter thought of as a generalized matrix\n",
    "###### We can have 1D, 2D, 3D, ND tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>vector = 1D Tensor<br>\n",
    "<br>Matrix = 2D Tensor<br>\n",
    "<br>Tensor >= 3D<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><tt>torch.Tensor</tt></strong></a> is a multi-dimensional matrix containing elements of a single data type.<br>\n",
    "Calculations between tensors can only happen if the tensors share the <u> same dtype.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "int32\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#creating numpy array to Companre\n",
    "arr = np.array([1,2,3,4,5])\n",
    "print(arr)\n",
    "print(arr.dtype)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Creating the 1-D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Carefully look at the DATA type'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INITIALIZING TENSOR\n",
    "x=torch.from_numpy(arr)\n",
    "\n",
    "#GloBAL = torch.as_tensor(arr)\n",
    "print(x)\n",
    "\n",
    "\"\"\"Carefully look at the DATA type\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "Data Type =  torch.int64\n",
      "Type =  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "#Using the \"as_tensor Command\"\n",
    "\n",
    "a=[1,2,3,4]\n",
    "y=torch.as_tensor(a)\n",
    "print(y)\n",
    "print(\"Data Type = \",y.dtype)\n",
    "print(\"Type = \",y.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Creating the 2-D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 2 - MATRIX\n",
    "arr= np.arange(0,12).reshape(4,3)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#creating tensor from MATRIX\n",
    "tensor_mat = torch.as_tensor(arr)\n",
    "print(tensor_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]\n",
      " [ 6.  7.  8.]\n",
      " [ 9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 3 - MATRIX\n",
    "arr= np.arange(0.0,12.0).reshape(4,3)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#creating tensor from MATRIX\n",
    "tensor_mat = torch.as_tensor(arr)\n",
    "print(tensor_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here \"torch.DoubleTensor\" refers to 64-bit floating point data.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Notice the Change in Dtype \"\"\"\n",
    "\"\"\" Here \"torch.DoubleTensor\" refers to 64-bit floating point data.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a> Changing the dtype of existing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8,  9, -3], dtype=torch.int32)\n",
      "torch.int32\n",
      "torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([8,9,-3], dtype=torch.int)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old type:  torch.IntTensor\n",
      "New type:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Change its type to torch.int64\n",
    "\n",
    "print(\"Old type: \",x.type())\n",
    "\n",
    "x=x.type(torch.int64)\n",
    "\n",
    "print(\"New type: \", x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a>Tensor Datatypes</a></h4>\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>TYPE</th><th>NAME</th><th>EQUIVALENT</th><th>TENSOR TYPE</th></tr>\n",
    "<tr><td>32-bit integer (signed)</td><td>torch.int32</td><td>torch.int</td><td>IntTensor</td></tr>\n",
    "<tr><td>64-bit integer (signed)</td><td>torch.int64</td><td>torch.long</td><td>LongTensor</td></tr>\n",
    "<tr><td>16-bit integer (signed)</td><td>torch.int16</td><td>torch.short</td><td>ShortTensor</td></tr>\n",
    "<tr><td>32-bit floating point</td><td>torch.float32</td><td>torch.float</td><td>FloatTensor</td></tr>\n",
    "<tr><td>64-bit floating point</td><td>torch.float64</td><td>torch.double</td><td>DoubleTensor</td></tr>\n",
    "<tr><td>16-bit floating point</td><td>torch.float16</td><td>torch.half</td><td>HalfTensor</td></tr>\n",
    "<tr><td>8-bit integer (signed)</td><td>torch.int8</td><td></td><td>CharTensor</td></tr>\n",
    "<tr><td>8-bit integer (unsigned)</td><td>torch.uint8</td><td></td><td>ByteTensor</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h4> Copying vs. sharing <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><strong><tt>torch.from_numpy()</tt></strong></a><br>\n",
    "<a><strong><tt>torch.as_tensor()</tt></strong></a><br>\n",
    "<a><strong><tt>torch.tensor()</tt></strong></a><br>\n",
    "\n",
    "There are a number of different functions available for <a>creating tensors</a>. \n",
    "<br> When using <a><strong><tt>torch.from_numpy()</tt></strong></a> and <a><strong><tt>torch.as_tensor()</tt></strong></a>, the PyTorch tensor and the source NumPy array share the same memory. </br>\n",
    "\n",
    "This means that changes to one affect the other. However, the <a><strong><tt>torch.tensor()</tt></strong></a> function always makes a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#using torch.from_numpy\n",
    "\n",
    "ar= np.arange(0,5)\n",
    "t=torch.from_numpy(ar)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginial ar =  [0 1 2 3 4]\n",
      "original tensor =  tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n",
      "ar after change in ar =  [ 0 -1  7  3  4]\n",
      "tensor after change in t =  tensor([ 0, -1,  7,  3,  4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# proof that they share same memory\n",
    "print(\"orginial ar = \",ar)\n",
    "print(\"original tensor = \",t)\n",
    "ar[2]=7\n",
    "t[1]=-1\n",
    "print(\"ar after change in ar = \",ar)\n",
    "print(\"tensor after change in t = \",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Class constructors </h4>\n",
    "<a><strong><tt>torch.Tensor()</tt></strong></a><br>\n",
    "<a><strong><tt>torch.FloatTensor()</tt></strong></a><br>\n",
    "<a><strong><tt>torch.LongTensor()</tt></strong></a>, etc.<br>\n",
    "\n",
    "There's a subtle difference between using the factory function <font color=red><tt>torch.tensor(data)</tt></font> and the class constructor <font color=red><tt>torch.Tensor(data)</tt></font>.<br>\n",
    "The factory function determines the dtype from the incoming data, or from a passed-in dtype argument.<br>\n",
    "The class constructor <tt>torch.Tensor()</tt>is simply an alias for <tt>torch.FloatTensor(data)</tt>. Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to cc = torch.FloatTensor(data)\n",
    "\n",
    "# It torch.Tensor() converts the data to FloatTensor (necessarily)\n",
    "a= torch.Tensor(data)\n",
    "print(a, a.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32) torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "# using torch.tensor()\n",
    "\n",
    "b = torch.tensor(data)\n",
    "print(b, b.type())\n",
    "\n",
    "#this does not explicitly change the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# using explicit conversion to torch.long\n",
    "\n",
    "c = torch.tensor(data, dtype=torch.long)\n",
    "print(c, c.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <a> Creating tensors from scratch </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uninitialized tensors with <tt>.empty()</tt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><strong><tt>torch.empty()</tt></strong></a> returns an <em>uninitialized</em> tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentially a block of memory is allocated according \n",
    "# to the size of the tensor.\n",
    "# This is similar to the behavior of <tt>numpy.empty()</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialized tensors with <tt>.zeros()</tt> and <tt>.ones()</tt>\n",
    "###### It's a good idea to pass in the intended dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#Creating a Zero Tensor of 4x3 size\n",
    "x= torch.zeros(4,3, dtype=torch.int64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "#Creating a One Tensor of 4x3 size\n",
    "x= torch.ones(4,3, dtype=torch.int64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <a>Tensors from ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><strong><tt>torch.arange(start,end,step)</tt></strong></a><br>\n",
    "<a><strong><tt>torch.linspace(start,end,steps)</tt></strong></a><br>\n",
    "Note that with <tt>.arange()</tt>, <tt>end</tt> is exclusive, while with <tt>linspace()</tt>, <tt>end</tt> is inclusive.\n",
    "\n",
    "<br> Same as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16])\n"
     ]
    }
   ],
   "source": [
    "#Using arange\n",
    "x=torch.arange(0,18,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.6364,  3.2727],\n",
      "        [ 4.9091,  6.5455,  8.1818],\n",
      "        [ 9.8182, 11.4545, 13.0909],\n",
      "        [14.7273, 16.3636, 18.0000]])\n"
     ]
    }
   ],
   "source": [
    "#using linspace\n",
    "x=torch.linspace(0,18,12).reshape(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a>Random number tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a><strong><tt>torch.rand(size)</tt></strong></a> returns random samples from a uniform dist over [0, 1)<br>\n",
    "<a><strong><tt>torch.randn(size)</tt></strong></a> returns samples from the \"standard normal\" dist [σ = 1]<br>\n",
    "Unlike <tt>rand</tt> which is uniform, values closer to zero are more likely to appear.<br>\n",
    "<a><strong><tt>torch.randint(low,high,size)</tt></strong></a> returns random integers from low (inclusive) to high (exclusive)<br>\n",
    "Same as Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1311, 0.1731, 0.8367],\n",
      "        [0.0046, 0.0186, 0.8609],\n",
      "        [0.3978, 0.6337, 0.1008],\n",
      "        [0.1572, 0.3382, 0.1770]])\n"
     ]
    }
   ],
   "source": [
    "# random samples from a uniform dist over [0, 1)\n",
    "x = torch.rand(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5506,  0.0601, -0.0161],\n",
      "        [ 0.0352, -1.0895,  1.6982],\n",
      "        [-1.8522, -0.5731,  0.4563],\n",
      "        [-0.6152,  1.0014, -1.4056]])\n"
     ]
    }
   ],
   "source": [
    "# returns samples from the \"standard normal\" dist [σ = 1]\n",
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 1],\n",
      "        [3, 4, 4],\n",
      "        [4, 3, 2],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "#Different \n",
    "# Generate random no in range\n",
    "x = torch.randint(0, 5, (4, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random number tensors that follow the input size\n",
    "<a><strong><tt>torch.rand_like(input)</tt></strong></a><br>\n",
    "<a><strong><tt>torch.randn_like(input)</tt></strong></a><br>\n",
    "<a><strong><tt>torch.randint_like(input,low,high)</tt></strong></a><br> these return random number tensors with the same size as <tt>input</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6246, -0.5785, -0.3368,  0.1028,  0.8726],\n",
      "        [-1.1405, -0.0407, -0.0814,  0.8923,  0.3031]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.randn_like(x)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same syntax can be used with<br>\n",
    "<a><strong><tt>torch.zeros_like(input)</tt></strong></a><br>\n",
    "<a><strong><tt>torch.ones_like(input)</tt></strong></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones_like(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>1. INDEXING and SLICING </a>\n",
    "\n",
    "same as Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 values =\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#generate 6 Values in 3x2 Matrix\n",
    "x= torch.arange(6).reshape(2,3)\n",
    "print(\"6 values =\\n\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All rows, of column index=1\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All rows and columns =0,1\n",
    "x[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a> 2. Reshape tensors with <tt>.view()</tt> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# torch.View usage\n",
    "x=x.view(2,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIGHLIGHT -Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Although both <a> torch.view </a> and <a> torch.reshape </a> are used to reshape tensors, here are the differences between them.\n",
    "\n",
    "<u>torch.view</u><br>\n",
    "As the name suggests, torch.view merely creates a view of the original tensor. The new tensor will always share its data with the original tensor. This means that if you change the original tensor, the reshaped tensor will change and vice versa.<br>\n",
    "\n",
    "To ensure that the new tensor always shares its data with the original, torch.view imposes some contiguity constraints on the shapes of the two tensors\n",
    "<h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(3, 2)\n",
    "x = z.view(2, 3)\n",
    "z.fill_(1)\n",
    "print(x)\n",
    "# we can see that x also changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4244/1218069508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "#place where view wont' work.\n",
    "z = torch.zeros(3, 2)\n",
    "y = z.t()\n",
    "y.size()\n",
    "torch.Size([2, 3])\n",
    "y.view(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> <u>torch.reshape </u> doesn't impose any contiguity constraints, but also doesn't guarantee data sharing.<br>\n",
    "\n",
    "The new tensor may be a view of the original tensor, or it may be a new tensor altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org X= \n",
      " tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "\n",
      "org y= \n",
      " tensor([0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "org z= \n",
      " tensor([0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Modified x= \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "Modified y= \n",
      " tensor([1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Modified z= \n",
      " tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(3, 2)\n",
    "print(\"org X= \\n\",x)\n",
    "y = x.reshape(6)\n",
    "print(\"\\norg y= \\n\",y)\n",
    "z = x.t().reshape(6)\n",
    "print(\"\\norg z= \\n\",z)\n",
    "\n",
    "x.fill_(1)\n",
    "\n",
    "print(\"\\nModified x= \\n\",x)\n",
    "print(\"\\nModified y= \\n\",y)\n",
    "print(\"\\nModified z= \\n\",z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a> Views can infer the correct size </a><br>\n",
    "By passing in <tt>-1</tt> PyTorch will infer the correct value from the given tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Suppose we want an 2xN dim tensor so that N will be taken care of by the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now you want a 2d vector but dont know how many columns will it fi into\n",
    "x.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3], dtype=torch.float)\n",
    "b=torch.tensor([4,5,6], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> <a> 3 ways to ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(b) #equivalent to a=torch.add(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>Any operation that changes a tensor in-place is post-fixed with an underscore _.\n",
    "    <br>In the above example: a.add__(b) changed <tt>a</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(torch.add(a,b).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h4>Dot products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot products can be expressed as <a><strong><tt>torch.dot(a,b)</tt></strong></a> or `a.dot(b)` or `b.dot(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a.mul(b)) # for reference\n",
    "print()\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h4> Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication computed using <a><strong><tt>torch.mm(a,b)</tt></strong></a> or `a.mm(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n",
      "a x b:  torch.Size([2, 2])\n",
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
    "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
    "\n",
    "print('a: ',a.size())\n",
    "print('b: ',b.size())\n",
    "print('a x b: ',torch.mm(a,b).size())\n",
    "print(torch.mm(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(2, 3, 4)\n",
    "t2 = torch.randn(4, 5)\n",
    "\n",
    "print(torch.matmul(t1, t2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the same operation raises a <tt><strong>RuntimeError</strong></tt> with <tt>torch.mm()</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4244/2270689567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "print(torch.mm(t1, t2).size())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
