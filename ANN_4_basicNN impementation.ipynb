{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PyTorch Neural Network\n",
    "\n",
    "* create a multi-layer deep learning model\n",
    "* load data\n",
    "* train and validate the model<br>\n",
    "\n",
    "* save and load a trained model(last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal -\n",
    "To develop a model capable of classifying an iris plant based on four features. \n",
    "\n",
    "- This is a multi-class classification where each sample can belong to ONE of 3 classes (<em>Iris setosa</em>, <em>Iris virginica</em> or <em>Iris versicolor</em>).\n",
    "- The network will have 4 input neurons (flower dimensions) and 3 output neurons (scores).\n",
    "- Our loss function will compare the target label (ground truth) to the corresponding output score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Create a Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - 4 features so 4 NEURONS\n",
    "# 2 hiden layers of 8, 9 NEURONS each\n",
    "# output layer  = 3 categories so , 3 NEURONS\n",
    "\n",
    "# pre activation function - (aggregator) - Linear function - W*X+B\n",
    "# Activation function - Relu\n",
    "\n",
    "# loss - Cross Entropy (as we need probabilities)\n",
    "# algorithm - Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___init__ should contain how many layers we need\n",
    "# input Layer (4 features) ---> h1 (8N) ---> h2 (9N) ---> O/P (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__ (self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        # fc1 - fully connected layer 1\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "        # for simplicity we used x in all three statements\n",
    "        # x1 = F.relu(self.fc1(x))\n",
    "        # x2 = F.relu(self.fc2(x1))\n",
    "        # x3 = self.out(x2)\n",
    "        # return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Model class using parameter defaults:\n",
    "torch.manual_seed(32)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Load the iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Data/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a> <h> Plot the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3> <u> Perform Train/Test/Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target',axis=1).values\n",
    "y= df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "# y_train = F.one_hot(torch.LongTensor(y_train))  # not needed with Cross Entropy Loss\n",
    "# y_test = F.one_hot(torch.LongTensor(y_test))\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><u><h3> Prepare DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our dataset is small (120 training samples), we'll load it into our model in two batches. This technique becomes very helpful with large datasets.\n",
    "\n",
    "Note that scikit-learn already shuffled the source dataset before preparing train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train, batch_size=60,shuffle=True)\n",
    "\n",
    "testloader = DataLoader(X_test, batch_size=60,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Define loss equations and optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR REDO\n",
    "torch.manual_seed(4)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function - cros Entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss: 1.09568226\n",
      "epoch:  1  loss: 1.08040512\n",
      "epoch:  2  loss: 1.07033861\n",
      "epoch:  3  loss: 1.06087792\n",
      "epoch:  4  loss: 1.05071282\n",
      "epoch:  5  loss: 1.03998208\n",
      "epoch:  6  loss: 1.02909625\n",
      "epoch:  7  loss: 1.01826751\n",
      "epoch:  8  loss: 1.00721562\n",
      "epoch:  9  loss: 0.99531204\n",
      "epoch: 10  loss: 0.98190629\n",
      "epoch: 11  loss: 0.96687967\n",
      "epoch: 12  loss: 0.95038033\n",
      "epoch: 13  loss: 0.93217224\n",
      "epoch: 14  loss: 0.91220015\n",
      "epoch: 15  loss: 0.89048469\n",
      "epoch: 16  loss: 0.86701298\n",
      "epoch: 17  loss: 0.84186012\n",
      "epoch: 18  loss: 0.81504059\n",
      "epoch: 19  loss: 0.78653044\n",
      "epoch: 20  loss: 0.75652379\n",
      "epoch: 21  loss: 0.72590339\n",
      "epoch: 22  loss: 0.69671160\n",
      "epoch: 23  loss: 0.66983062\n",
      "epoch: 24  loss: 0.64395487\n",
      "epoch: 25  loss: 0.61811143\n",
      "epoch: 26  loss: 0.59124285\n",
      "epoch: 27  loss: 0.56446719\n",
      "epoch: 28  loss: 0.53923553\n",
      "epoch: 29  loss: 0.51587290\n",
      "epoch: 30  loss: 0.49447367\n",
      "epoch: 31  loss: 0.47492424\n",
      "epoch: 32  loss: 0.45280999\n",
      "epoch: 33  loss: 0.43679962\n",
      "epoch: 34  loss: 0.42453590\n",
      "epoch: 35  loss: 0.41129914\n",
      "epoch: 36  loss: 0.39777330\n",
      "epoch: 37  loss: 0.38543823\n",
      "epoch: 38  loss: 0.37434873\n",
      "epoch: 39  loss: 0.36267132\n",
      "epoch: 40  loss: 0.34981725\n",
      "epoch: 41  loss: 0.33777708\n",
      "epoch: 42  loss: 0.32672301\n",
      "epoch: 43  loss: 0.31426513\n",
      "epoch: 44  loss: 0.30094174\n",
      "epoch: 45  loss: 0.28898498\n",
      "epoch: 46  loss: 0.27690026\n",
      "epoch: 47  loss: 0.26386702\n",
      "epoch: 48  loss: 0.25232512\n",
      "epoch: 49  loss: 0.24050036\n",
      "epoch: 50  loss: 0.22807980\n",
      "epoch: 51  loss: 0.21720470\n",
      "epoch: 52  loss: 0.20577021\n",
      "epoch: 53  loss: 0.19522251\n",
      "epoch: 54  loss: 0.18532853\n",
      "epoch: 55  loss: 0.17519450\n",
      "epoch: 56  loss: 0.16649503\n",
      "epoch: 57  loss: 0.15754074\n",
      "epoch: 58  loss: 0.14990349\n",
      "epoch: 59  loss: 0.14223678\n",
      "epoch: 60  loss: 0.13547555\n",
      "epoch: 61  loss: 0.12908033\n",
      "epoch: 62  loss: 0.12328939\n",
      "epoch: 63  loss: 0.11799251\n",
      "epoch: 64  loss: 0.11304948\n",
      "epoch: 65  loss: 0.10867288\n",
      "epoch: 66  loss: 0.10454611\n",
      "epoch: 67  loss: 0.10093752\n",
      "epoch: 68  loss: 0.09748480\n",
      "epoch: 69  loss: 0.09449016\n",
      "epoch: 70  loss: 0.09162237\n",
      "epoch: 71  loss: 0.08912913\n",
      "epoch: 72  loss: 0.08673408\n",
      "epoch: 73  loss: 0.08464032\n",
      "epoch: 74  loss: 0.08264378\n",
      "epoch: 75  loss: 0.08087306\n",
      "epoch: 76  loss: 0.07919822\n",
      "epoch: 77  loss: 0.07768469\n",
      "epoch: 78  loss: 0.07627789\n",
      "epoch: 79  loss: 0.07497228\n",
      "epoch: 80  loss: 0.07378435\n",
      "epoch: 81  loss: 0.07264890\n",
      "epoch: 82  loss: 0.07163962\n",
      "epoch: 83  loss: 0.07064617\n",
      "epoch: 84  loss: 0.06977896\n",
      "epoch: 85  loss: 0.06891181\n",
      "epoch: 86  loss: 0.06815489\n",
      "epoch: 87  loss: 0.06740073\n",
      "epoch: 88  loss: 0.06672581\n",
      "epoch: 89  loss: 0.06607464\n",
      "epoch: 90  loss: 0.06546316\n",
      "epoch: 91  loss: 0.06489849\n",
      "epoch: 92  loss: 0.06434345\n",
      "epoch: 93  loss: 0.06384435\n",
      "epoch: 94  loss: 0.06334655\n",
      "epoch: 95  loss: 0.06289093\n",
      "epoch: 96  loss: 0.06245120\n",
      "epoch: 97  loss: 0.06202797\n",
      "epoch: 98  loss: 0.06163653\n",
      "epoch: 99  loss: 0.06124767\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "# a neat trick to save screen space:\n",
    "#if i%10 == 0:\n",
    "    print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Plot the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Validate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Torch.no_grad() deactivates autograd engine.\n",
    "\n",
    "- Eventually it will reduce the memory usage and speed up computations.\n",
    "\n",
    "- Use of Torch.no_grad():\n",
    "\n",
    "    * To perform inference without Gradient Calculation.\n",
    "\n",
    "    * To make sure there's no leak test data into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06247772\n"
     ]
    }
   ],
   "source": [
    "# To Evaluate the Entire Test set\n",
    "# no_grad ensure that gradient is not calculated and weights and bias are not updated\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    loss = criterion(y_val , y_test)\n",
    "print(f'{loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loss tells us that we are not overfitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([-0.3360,  7.3629,  1.3780])     1\n",
      " 2. tensor([0.2770, 8.1552, 0.4267])        1\n",
      " 3. tensor([ 11.9968,   6.1842, -19.1980])  0\n",
      " 4. tensor([-2.0192,  7.9662,  4.2445])     1\n",
      " 5. tensor([-6.1353,  7.9516, 11.0908])     2\n",
      " 6. tensor([-10.2640,   8.3102,  17.9992])  2\n",
      " 7. tensor([ 12.0541,   6.4316, -19.2913])  0\n",
      " 8. tensor([ 12.9496,   6.4815, -20.7530])  0\n",
      " 9. tensor([-5.7727,  8.2435, 10.5079])     2\n",
      "10. tensor([-7.8872,  8.6126, 14.0726])     2\n",
      "11. tensor([-8.7060,  8.6074, 15.4331])     2\n",
      "12. tensor([ 11.6348,   5.8164, -18.6210])  0\n",
      "13. tensor([-8.1013,  8.2331, 14.3883])     2\n",
      "14. tensor([-2.0796,  7.7751,  4.3185])     1\n",
      "15. tensor([-6.0833,  8.3916, 11.0582])     2\n",
      "16. tensor([0.1354, 7.8658, 0.6407])        1\n",
      "17. tensor([-4.0880,  7.7216,  7.6638])     2\n",
      "18. tensor([ 13.1511,   6.5907, -21.0787])  0\n",
      "19. tensor([-1.5649,  8.0220,  3.4751])     1\n",
      "20. tensor([-6.2865,  8.9727, 11.4244])     2\n",
      "21. tensor([ 12.3848,   6.2568, -19.8265])  0\n",
      "22. tensor([ 13.8199,   7.0854, -22.1532])  0\n",
      "23. tensor([-8.8475,  8.3181, 15.6471])     2\n",
      "24. tensor([ 12.1968,   6.1261, -19.5250])  0\n",
      "25. tensor([-5.8089,  7.5468, 10.5336])     2\n",
      "26. tensor([-4.4530,  7.7875,  8.2861])     2\n",
      "27. tensor([-1.4289,  7.7785,  3.2325])     1\n",
      "28. tensor([ 0.5351,  7.5358, -0.0494])     1\n",
      "29. tensor([-5.8235,  8.1573, 10.5971])     2\n",
      "30. tensor([-5.2573,  7.7475,  9.6101])     2\n",
      "\n",
      "29 out of 30 = 96.67%  correct\n"
     ]
    }
   ],
   "source": [
    "# to print out the results on Test DataSet\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(\"{:2}. {:38}  {}\".format(i+1, str(y_val), y_test[i]))\n",
    "        \n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct= correct+1\n",
    "\n",
    "print(\"\\n{} out of {} = {:.2f}%  correct\".format(correct, len(y_test), 100*correct/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Save the Trained model to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save this on disk.<br>\n",
    "The tools we'll use are <a><strong><tt>torch.load()</tt></strong></a><br>\n",
    "\n",
    "There are two basic ways to save a model.<br>\n",
    "\n",
    "The first saves/loads the `state_dict` (learned parameters) of the model, but not the model class. The syntax follows:<br>\n",
    "<tt><strong>Save:</strong>&nbsp;torch.save(model.state_dict(), PATH)<br><br>\n",
    "<strong>Load:</strong>&nbsp;model = TheModelClass(\\*args, \\*\\*kwargs)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.load_state_dict(torch.load(PATH))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.eval()</tt>\n",
    "\n",
    "The second saves the entire model including its class and parameters as a pickle file. Care must be taken if you want to load this into another notebook to make sure all the target data is brought in properly.<br>\n",
    "<tt><strong>Save:</strong>&nbsp;torch.save(model, PATH)<br><br>\n",
    "<strong>Load:</strong>&nbsp;model = torch.load(PATH))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.eval()</tt>\n",
    "\n",
    "In either method, you must call <tt>model.eval()</tt> to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a> Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Saved_Models/IrisDatasetModel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Load a new Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load('Saved_Models/IrisDatasetModel.pt'))\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06247772\n"
     ]
    }
   ],
   "source": [
    "# checking on test set loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><h3><u> Apply the model to classify new, unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_iris = torch.tensor([5.6,3.7,2.2,0.5])\n",
    "labels = ['Iris setosa','Iris virginica','Iris versicolor','Mystery iris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 12.2112,   7.1279, -19.5248])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # This returns a tensor with 3 values, having value of each class\n",
    "    print(new_model(mystery_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that class-0 has highest value\n",
    "# argmax returns maximum value index no\n",
    " \n",
    "new_model(mystery_iris).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species -  Iris setosa\n"
     ]
    }
   ],
   "source": [
    "print(\"Species - \",labels[new_model(mystery_iris).argmax()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
